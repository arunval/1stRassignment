#####################################################################################

# 1. Business Understanding: 

# Pixilated images of numbers 0-9 captured have to be classified
# 1. Image attributes given 
# 2. Stratification of samples required to focus on individual number-image attributes

# Based on the pixel properties,our objective is to identify image correctly.

#####################################################################################

# 2. Data Understanding: 
# http://corochann.com/mnist-dataset-introduction-1138.html
# Number of Instances: 60000
# Number of Attributes: 784 

#3. Data Preparation: 

##Loading Neccessary libraries

library(kernlab)
library(readr)
library(caret)
library(caTools)
library(h2o) # For parallel processing

#Loading Data
train <- read.csv("MNIST_train.csv", header = F)
test <- read.csv("MNIST_test.csv", header = F)


# Renaming the column names

colnames(train)[1] <- "digit"  
colnames(test)[1] <- "digit"  

#Understanding Dimensions
dim(train)

#Structure of the dataset
str(train)

#printing first few rows
head(train)

#Exploring the data
summary(train)

# Changing output variable "spam" to factor type 

train$digit <- as.factor(train$digit)
test$digit <- as.factor(test$digit)


# Checking missing value
sapply(train, function(x) sum(is.na(x))) # No missing values


#####################################################################################

# Stratified split of the data as per digits
install.packages("splitstackshape")
library(splitstackshape)

set.seed(100)

train.out <- stratified(train, c("digit"), 200)

test.out <- stratified(test, c("digit"), 200)



# 4. Model Building

#--------------------------------------------------------------------
# 4.1 Linear model - SVM  at Cost(C) = 1
#####################################################################

# Model with C =1
model_1<- ksvm(digit ~ ., data = train.out,scale = FALSE,C=1)

# Predicting the model results 
evaluate_1<- predict(model_1, test.out)

# Confusion Matrix - Finding accuracy, Sensitivity and specificity
confusionMatrix(evaluate_1, test.out$digit)

# Accuracy    : 0.9395


#--------------------------------------------------------------------
# 4.2 Linear model - SVM  at Cost(C) = 10
#####################################################################

# Model with C =10.
model_10<- ksvm(digit ~ ., data = train.out,scale = FALSE,C=10)

# Predicting the model results
evaluate_10<- predict(model_10, test.out)

# Confusion Matrix - finding accuracy, sensitivity and specificity
confusionMatrix(evaluate_10, test.out$digit)

# Accuracy    : 0.9425

#####################################################################

#####################################################################
# 4.3 Hyperparameter tuning and Cross Validation  - Linear - SVM 
######################################################################

# We will use the train function from caret package to perform crossvalidation

trainControl <- trainControl(method="cv", number=5)
# Number - Number of folds 
# Method - cross validation

metric <- "Accuracy"

set.seed(100)


# making a grid of C values. 
grid <- expand.grid(C=seq(1, 5, by=1))

# Performing 5-fold cross validation
fit.svm <- train(digit~., data=train, method="svmLinear", metric=metric, 
                 tuneGrid=grid, trControl=trainControl)

# Printing cross validation result
print(fit.svm)
# Best tune at C= 1, 
# Accuracy : 0.873

# Plotting "fit.svm" results
plot(fit.svm)

###############################################################################

# Valdiating the model after cross validation on test data

evaluate_linear_test<- predict(fit.svm, test.out)
confusionMatrix(evaluate_linear_test, test.out$digit)

# Accuracy    : 0.896

#4.4 Non-Linear - Kernels
######################################################################

# RBF kernel 
model_rbf <- ksvm(digit ~ ., data =train.out,scale=FALSE, kernel = "rbfdot")

# Predicting the model results 
Eval_RBF<- predict(model_rbf, test.out)

#confusion matrix - RBF Kernel
confusionMatrix(Eval_RBF,test.out$digit)

# Accuracy    : 0.9395

#####################################################################
# 4.5 Hyperparameter tuning and Cross Validation - Non-Linear - SVM 
######################################################################

# We will use the train function from caret package to perform crossvalidation

# Making grid of "sigma" and C values. 
grid <- expand.grid(.sigma=seq(0.0000001, 0.0000005, by=0.0000001), .C=seq(1, 5, by=1))

# Performing 5-fold cross validation
fit.svm_radial <- train(digit~., data=train.out, method="svmRadial", metric=metric, 
                        tuneGrid=grid, trControl=trainControl)

# Printing cross validation result
print(fit.svm_radial)
# Best tune at sigma = 3e-07 and C = 2, Accuracy - 0.9315

# Plotting model results
plot(fit.svm_radial)

######################################################################
# Checking overfitting - Non-Linear - SVM
######################################################################

# Validating the model results on test data
evaluate_non_linear<- predict(fit.svm_radial, test.out)
confusionMatrix(evaluate_non_linear, test.out$digit)

# Accuracy    - 0.949
